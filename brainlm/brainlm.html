<!doctype html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
	<title>BrainLM: A Foundation Model for fMRI</title>
	<link rel="stylesheet" href="dist/reset.css">
	<link rel="stylesheet" href="dist/reveal.css">
	<link rel="stylesheet" href="dist/theme/black.css" id="theme">
	<style>
		/* :root {
			--r-main-font-size: 32px;
			--r-heading1-size: 1.8em;
			--r-heading2-size: 1.4em;
			--r-heading3-size: 1.1em;
		} */
		/* .reveal {
			font-size: var(--r-main-font-size);
		} */
		.reveal h1 {
			color: #14b8a6;
			/* font-size: var(--r-heading1-size); */
			margin-bottom: 0.4em;
		}
		.reveal h2 {
			color: #14b8a6;
			/* font-size: var(--r-heading2-size); */
			margin-bottom: 0.3em;
		}
		.reveal h3 {
			color: #8b5cf6;
			/* font-size: var(--r-heading3-size); */
			margin-bottom: 0.3em;
		}
		.reveal ul, .reveal ol {
			/* font-size: 0.85em; */
			margin-left: 0.5em;
		}
		.reveal li {
			margin-bottom: 0.4em;
			line-height: 1.3;
		}
		.reveal strong {
			color: #f472b6;
		}
		.reveal .highlight {
			color: #14b8a6;
			font-weight: bold;
		}
		.reveal .slides section {
			height: 100%;
			padding: 20px 40px;
		}
		.reveal img {
			max-height: 55vh;
			border: none;
			box-shadow: 0 4px 20px rgba(0,0,0,0.3);
			border-radius: 8px;
		}
		.reveal .title-slide {
			text-align: center;
		}
		.reveal .title-slide h1 {
			/* font-size: 2.2em; */
			margin-bottom: 0.2em;
		}
		.reveal .title-slide h2 {
			/* font-size: 1em; */
			color: #8b5cf6;
			font-weight: normal;
		}
		.reveal .two-col {
			display: flex;
			gap: 30px;
			align-items: flex-start;
		}
		.reveal .two-col > div {
			flex: 1;
		}
		.reveal .two-col img {
			max-width: 100%;
			max-height: 50vh;
		}
		.reveal .fig-caption {
			/* font-size: 0.6em; */
			color: #888;
			text-align: center;
			margin-top: 5px;
		}
		.reveal .stats-row {
			display: flex;
			justify-content: space-around;
			margin: 20px 0;
		}
		.reveal .stat-box {
			background: rgba(20, 184, 166, 0.15);
			border: 1px solid #14b8a6;
			border-radius: 8px;
			padding: 15px 25px;
			text-align: center;
		}
		.reveal .stat-box .number {
			/* font-size: 1.8em; */
			color: #14b8a6;
			font-weight: bold;
		}
		.reveal .stat-box .label {
			/* font-size: 0.7em; */
			color: #aaa;
		}
		.reveal table {
			/* font-size: 0.75em; */
			margin: 10px auto;
		}
		.reveal table th {
			background: rgba(20, 184, 166, 0.2);
			color: #14b8a6;
		}
		.reveal table td, .reveal table th {
			padding: 8px 15px;
			border: 1px solid #333;
		}
		.reveal .center-img {
			text-align: center;
		}
		.reveal .center-img img {
			max-height: 58vh;
		}
	</style>
</head>
<body>
	<div class="reveal">
		<div class="slides">

			<!-- Title Slide -->
			<section>
				<h1>BrainLM</h1>
				<h3>A Foundation Model for Interpretable and Generalizable Analysis of Human Brain Activity</h3>
				<p><strong>Aakash Patel</strong></p>
				<p><small>Department of Computer Science, Yale University</small></p>
			</section>

			<!-- Foundation Model Concept -->
			<section>
				<h2>The "Foundation" Model Concept</h2>
				<div class="two-col">
					<div>
						<p class="fragment" style="text-align: left;"><strong>Traditional AI:</strong> Narrowly defined tasks, limited generalization</p>
						<img class="fragment" src="assets/traditional_ml_vs_foundation.jpg" alt="Traditional ML vs Foundation Models">
					</div>
					<div>
						<p class="fragment" style="text-align: left;"><strong>Foundation Models:</strong></p>
						<ul>
							<li class="fragment">Trained on vast, heterogeneous data</li>
							<li class="fragment">Self-supervised learning</li>
							<li class="fragment">Adaptable to diverse applications</li>
						</ul>
						<p class="fragment"><small><em>Image generated by Google Gemini</em></small></p>
					</div>
				</div>
			</section>

			<!-- How Foundation Models Learn -->
			<section>
				<h2>How Foundation Models "Learn"</h2>
				<h3>The "Fill-in-the-Blank" Approach</h3>
				<ul>
					<li class="fragment"><strong>Self-Supervision:</strong> Hide parts of data → reconstruct</li>
					<li class="fragment"><strong>Masking:</strong> Minimize reconstruction error</li>
					<li class="fragment"><strong>Result:</strong> Model learns underlying structure</li>
				</ul>
				<p class="fragment"><small><em>Similar to a "cloze test" — predict the missing word/data</em></small></p>
			</section>

			<!-- fMRI Challenge -->
			<section>
				<h2>The Challenge of fMRI Analysis</h2>
				<ul>
					<li class="fragment"><strong>Data Complexity:</strong> High-dimensional, non-linear</li>
					<li class="fragment"><strong>Variability:</strong> Across scanners, sites, cohorts</li>
					<li class="fragment"><strong>Generalization Gap:</strong> Models fail on new datasets</li>
					<li class="fragment"><strong>Data Scarcity:</strong> Prior work used small datasets</li>
				</ul>
			</section>

			<!-- Introducing BrainLM -->
			<section>
				<h2>Introducing BrainLM</h2>
				<p class="fragment"><strong>6,700 hours</strong> of fMRI data</p>
				<p class="fragment"><strong>77,000</strong> recordings from <strong>42,000</strong> subjects (UK Biobank)</p>
				<img class="fragment" src="assets/fig1_brainlm_overview.png" alt="Figure 1: BrainLM Overview" style="max-height: 40vh;">
				<p><small>BrainLM Framework Overview</small></p>
			</section>

			<!-- ROI parcellation -->
			<section>
				<h2>ROI Parcellation</h2>
				<div class="two-col">
					<div>
						<ul>
							<li class="fragment"><strong>Preprocessing:</strong> Motion distortion correction, denoising, temporal filtering, and framewise displacement correction.</li>
							<li class="fragment">Volumes moothed to 4 mm FWHM and parcellated into 424 functional regions.</li>
						</ul>
					</div>
					<div>
						<img src="assets/roi_parcellation.png" alt="ROI Parcellation" class="r-stretch">
						<p><small>ROI Parcellation</small></p>
					</div>
				</div>
			</section>


			<!-- Spatiotemporal Masking -->
			<section>
				<h2>Spatiotemporal Masking</h2>
				<img src="assets/masking_strategy.png" alt="Spatiotemporal Masking" class="r-stretch">
				<p><small>Spatiotemporal Masking: Randomly mask 200 time-step windows</small></p>
			</section>


			<!-- Training Methodology -->
			<section>
				<h2>Model Architecture</h2>
				<img src="assets/masked_autoencoder.png" alt="Model Architecture" class="r-stretch">
				<p><small>Model Architecture: Masked Autoencoder</small></p>
			</section>

			<!-- Forecasting -->
			<section>
				<h2>Forecasting Brain States</h2>
				<h3>Generalization to New Cohorts</h3>
				<div class="two-col">
					<div>
						<ul>
							<li class="fragment"><strong>Task:</strong> Predict next 20 time-steps</li>
							<li class="fragment"><strong>Top:</strong> Unseen patients from UKB</li>
							<li class="fragment"><strong>Bottom:</strong> Completely unseen data from HCP</li>
						</ul>
					</div>
					<div>
						<img src="assets/unseen_data_reconstruction.png" alt="Forecasting" style="max-height: 40vh;">
						<p><small>BrainLM (red) matches ground truth (black) on UK Biobank and HCP</small></p>
					</div>
				</div>
			</section>

			<!-- Latent Space -->
			<section>
				<h2>The Latent Space</h2>
				<h4>Self-organized by clinical dimensions</h4>
				<div class="center-img">
					<img src="assets/latent_space.png" alt="Latent Space" style="max-height: 40vh;">
					<p class="fig-caption">UMAP shows organization by age (color) and task vs rest (clusters)</p>
				</div>
			</section>

			<!-- Clinical Prediction -->
			<section>
				<h2>Clinical Variable Prediction</h2>
				<ul>
					<li class="fragment"><strong>Task:</strong> Predict Age, Anxiety (GAD-7), PTSD (PCL-5), Neuroticism</li>
					<li class="fragment"><strong>Result:</strong> BrainLM achieved the lowest MSE vs baselines (LSTM, GCN, SVR)</li>
				</ul>
				<img src="assets/performance_benchmarking.png" alt="Clinical Variable Prediction" class="r-stretch">
			</section>

			<!-- Brain Age Gap -->
			<section>
				<h2>Brain Age Gap</h2>
				<ul>
					<li class="fragment">Psychiatric conditions → "accelerated brain aging"</li>
					<li class="fragment">Predict age, calculate residual (true - predicted age)</li>
					<li class="fragment"><strong>Finding:</strong> High psychiatric scores → elevated brain age gap</li>
				</ul>
				<img class="fragment" src="assets/brain_age_gap.png" alt="Brain Age Gap" style="max-height: 280px;">
			</section>

			<!-- Treatment Effects -->
			<section>
				<h2>Can Treatment Reverse Brain Aging?</h2>
				<img src="assets/embarc_age_prediction.png" alt="EMBARC Age Prediction" class="r-stretch">
				<p class="fragment"><small>EMBARC trial: Mean change <strong>-0.70 years</strong> after one week — brain age is state-dependent</small></p>
			</section>

			<!-- Attention Maps -->
			<section>
				<h2>Interpretability: Attention Maps</h2>
				<img src="assets/attention_analysis.png" alt="Figure 9" class="r-stretch">
				<p class="fragment"><small>High depression → reduced attention in sgACC (emotion regulation) — aligns with pathophysiology</small></p>
			</section>

			<!-- Zero-Shot Networks -->
			<section>
				<h2>Zero-Shot Functional Networks</h2>
				<ul>
					<li class="fragment"><strong>Task:</strong> Segment brain into functional networks</li>
					<li class="fragment"><strong>Method:</strong> Use attention weights, no labels</li>
					<li class="fragment"><strong>Result:</strong> BrainLM achieves <strong>58.8%</strong> accuracy (vs GCN 25.9%)</li>
				</ul>
			</section>

			<!-- Summary -->
			<section>
				<h2>Summary</h2>
				<ul>
					<li class="fragment"><strong>First foundation model for fMRI</strong> at scale</li>
					<li class="fragment"><strong>Generalizes</strong> to new scanners and cohorts</li>
					<li class="fragment"><strong>Clinical utility:</strong> Predicts psychiatric variables</li>
					<li class="fragment"><strong>Interpretable:</strong> Attention maps align with neuroscience</li>
				</ul>
				<p class="fragment"><strong>Future:</strong> Integration with EEG, Genomics, expanded atlases</p>
			</section>

			<!-- Acknowledgments -->
			<section>
				<h2>Acknowledgments</h2>
				<p class="fragment"><strong>Collaborators:</strong> Josue Ortega Caro, Jaewon Chung, Syed A. Rizvi, Jans Solano, Christopher Averill, Antonio H. de O. Fonseca, Matteo Rosati, <strong>David van Dijk & Chadi G. Abdallah</strong></p>
				<p class="fragment"><strong>Support:</strong> Yale Wu Tsai Institute</p>
				<p class="fragment"><strong>van Dijk Lab:</strong> <a href="https://www.vandijklab.org">https://www.vandijklab.org</a></p>
				<p class="fragment"><strong>Code:</strong> <a href="https://github.com/vandijklab/BrainLM">github.com/vandijklab/BrainLM</a></p>
			</section>
		</div>
	</div>

	<script src="dist/reveal.js"></script>
	<script>
		Reveal.initialize({
			hash: true,
			controls: true,
			progress: true,
			center: true,
			transition: 'slide'
		});
	</script>
</body>
</html>
